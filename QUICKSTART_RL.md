# GPTFuzzer Stage 3: Reinforcement Learning å¿«é€Ÿå…¥é—¨

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆPPOç®—æ³•ï¼‰è®­ç»ƒWAFç»•è¿‡æ¨¡å‹ã€‚

---

## ğŸ“‹ å‰ç½®æ¡ä»¶

åœ¨å¼€å§‹RLè®­ç»ƒä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®Œæˆï¼š

âœ… **Stage 1: é¢„è®­ç»ƒ** - å®Œæˆè¯­æ³•å­¦ä¹   
   - æ¨¡å‹ä½ç½®: `./models/pretrain_sqli_gpt2_small/`
   - è®­ç»ƒè„šæœ¬: `train_sqli.ps1`

âœ… **Stage 2: å¥–åŠ±æ¨¡å‹** - è®­ç»ƒWAFåˆ†ç±»å™¨  
   - æ¨¡å‹ä½ç½®: `./models/reward_sqli/final_reward_model/`
   - è®­ç»ƒè„šæœ¬: `train_reward_sqli.ps1`

âœ… **ç¯å¢ƒé…ç½®**  
   - Python 3.8+
   - PyTorch 2.0+
   - CUDA (æ¨èï¼Œå¦åˆ™è®­ç»ƒéå¸¸æ…¢)
   - ä¾èµ–åŒ…: `pip install -r train/requirements_train.txt`

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1: ä½¿ç”¨PowerShellè„šæœ¬ (æ¨è)

```powershell
# ç›´æ¥è¿è¡Œï¼Œè‡ªåŠ¨æ£€æŸ¥ç¯å¢ƒå’Œæ¨¡å‹
.\train_rl_sqli.ps1
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- âœ… æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹å’Œå¥–åŠ±æ¨¡å‹æ˜¯å¦å­˜åœ¨
- âœ… æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
- âœ… é…ç½®è®­ç»ƒå‚æ•°ï¼ˆä½¿ç”¨è®ºæ–‡æ¨èå€¼ï¼‰
- âœ… å¼€å§‹è®­ç»ƒ

### æ–¹æ³•2: ç›´æ¥ä½¿ç”¨Python

```bash
python train/train_rl.py \
    --pretrained_model ./models/pretrain_sqli_gpt2_small \
    --reward_model ./models/reward_sqli/final_reward_model \
    --output_dir ./models/rl_sqli_gpt2 \
    --total_episodes 20 \
    --batch_size 256 \
    --mini_batch_size 16 \
    --init_kl_coef 0.2 \
    --learning_rate 1.4e-5
```

---

## âš™ï¸ æ ¸å¿ƒå‚æ•°è¯´æ˜

### å¿…éœ€å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--pretrained_model` | Stage 1çš„é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ | `./models/pretrain_sqli_gpt2_small` |
| `--reward_model` | Stage 2çš„å¥–åŠ±æ¨¡å‹è·¯å¾„ | `./models/reward_sqli/final_reward_model` |
| `--output_dir` | è¾“å‡ºç›®å½• | `./models/rl_sqli_gpt2` |

### PPOè¶…å‚æ•° (æ¥è‡ªè®ºæ–‡)

| å‚æ•° | è®ºæ–‡æ¨èå€¼ | è¯´æ˜ |
|------|-----------|------|
| `--learning_rate` | **1.4e-5** | å­¦ä¹ ç‡ï¼Œéå¸¸å°ä»¥é¿å…å¿˜è®°è¯­æ³• |
| `--batch_size` | **256** | æ¯è½®ç”Ÿæˆçš„æ ·æœ¬æ•° |
| `--mini_batch_size` | **16** | PPOæ›´æ–°çš„mini batch (æ˜¾å­˜ä¼˜åŒ–) |
| `--init_kl_coef` (Î²) | **0.2** | ğŸ”¥ **æœ€å…³é”®å‚æ•°**ï¼Œæ§åˆ¶KLæ•£åº¦æƒ©ç½š |
| `--ppo_epochs` | **4** | PPOå†…éƒ¨æ›´æ–°è½®æ•° |

### è®­ç»ƒæ§åˆ¶

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--total_episodes` | 20 | æ€»è®­ç»ƒè½®æ•° |
| `--max_new_tokens` | 128 | æ¯æ¬¡ç”Ÿæˆçš„æœ€å¤§tokenæ•° |
| `--save_freq` | 5 | æ¯Nè½®ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹ |
| `--temperature` | 1.0 | ç”Ÿæˆæ¸©åº¦ (0.1-2.0) |
| `--seed` | 42 | éšæœºç§å­ |

---

## ğŸ“Š è®­ç»ƒè¿‡ç¨‹ç†è§£

### PPOå·¥ä½œæµç¨‹

æ¯ä¸ªè®­ç»ƒè½®æ¬¡ï¼ˆEpisodeï¼‰åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š

```
1. ğŸ² Generate (Rollout)
   ä½¿ç”¨å½“å‰ç­–ç•¥ç½‘ç»œç”Ÿæˆ batch_size ä¸ªè½½è·
   
2. ğŸ Calculate Rewards
   å¥–åŠ±æ¨¡å‹è¯„ä¼°æ¯ä¸ªè½½è·çš„WAFç»•è¿‡æ¦‚ç‡ (0-1)
   
3. ğŸ”„ PPO Update
   æ ¹æ®å¥–åŠ±å’ŒKLæ•£åº¦æ›´æ–°ç­–ç•¥ç½‘ç»œå‚æ•°
   
4. ğŸ’¾ Save Checkpoint
   å®šæœŸä¿å­˜æ¨¡å‹
```

### å¥–åŠ±å‡½æ•°è®¾è®¡ (è®ºæ–‡æ ¸å¿ƒ)

```
R_total = R_WAF - Î² Â· KL(Ï€_Î¸, Ï)
```

- **R_WAF**: å¥–åŠ±æ¨¡å‹è¾“å‡ºçš„ç»•è¿‡æ¦‚ç‡ (0-1)
  - åªåœ¨ç”Ÿæˆç»“æŸæ—¶ç»™äºˆï¼ˆæœ€åä¸€ä¸ªtokenï¼‰
  
- **KL(Ï€_Î¸, Ï)**: KLæ•£åº¦æƒ©ç½š
  - è¡¡é‡å½“å‰ç­–ç•¥ä¸åŸå§‹é¢„è®­ç»ƒæ¨¡å‹çš„åç¦»ç¨‹åº¦
  - æ¯ä¸ªç”Ÿæˆæ­¥éª¤éƒ½è®¡ç®—
  
- **Î²**: KLç³»æ•°ï¼ˆè®ºæ–‡æ¨è0.2ï¼‰
  - å¤ªå°: æ¨¡å‹è¿‡åº¦ä¼˜åŒ–å¥–åŠ±ï¼Œå¯èƒ½ç”Ÿæˆæ— æ•ˆè¯­æ³•
  - å¤ªå¤§: æ¨¡å‹ä¸æ•¢åç¦»é¢„è®­ç»ƒï¼Œéš¾ä»¥å­¦åˆ°ç»•è¿‡æŠ€å·§

---

## ğŸ“ˆ ç›‘æ§è®­ç»ƒè¿›åº¦

### å…³é”®æŒ‡æ ‡

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè¾“å‡ºä»¥ä¸‹æŒ‡æ ‡ï¼š

```
ğŸ“Š å¥–åŠ±ç»Ÿè®¡:
   - å¹³å‡å¥–åŠ±: 0.1234    # åº”è¯¥é€æ¸ä¸Šå‡
   - æœ€å¤§å¥–åŠ±: 0.8901    # æœ€å¥½çš„æ ·æœ¬
   - æœ€å°å¥–åŠ±: 0.0012    # æœ€å·®çš„æ ·æœ¬

ğŸ”„ PPOæ›´æ–°:
   - PPOå¹³å‡åˆ†æ•°: 0.1234
   - KLæ•£åº¦: 0.0567       # åº”è¯¥ä¿æŒåœ¨0.1å·¦å³
   - æ€»æŸå¤±: 1.234
```

### æ”¶æ•›æ ‡å‡†

- **åˆå§‹é˜¶æ®µ** (Episodes 1-5):
  - å¹³å‡å¥–åŠ±: 0.01 ~ 0.1
  - æ¨¡å‹åœ¨æ¢ç´¢å„ç§å˜ä½“
  
- **ä¸­æœŸ** (Episodes 6-15):
  - å¹³å‡å¥–åŠ±: 0.1 ~ 0.3
  - æ¨¡å‹æ‰¾åˆ°ä¸€äº›æœ‰æ•ˆçš„ç»•è¿‡æ¨¡å¼
  
- **æ”¶æ•›** (Episodes 16-20):
  - å¹³å‡å¥–åŠ±: 0.3 ~ 0.5+ (å–å†³äºWAFéš¾åº¦)
  - å¥–åŠ±ç¨³å®šï¼Œä¸å†å¤§å¹…æ³¢åŠ¨

---

## ğŸ§ª æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¿å­˜åœ¨ `./models/rl_sqli_gpt2/final_model/`

### 1. å¿«é€Ÿæµ‹è¯•ç”Ÿæˆæ•ˆæœ

```bash
python train/test_rl_model.py \
    --model_path ./models/rl_sqli_gpt2/final_model \
    --num_samples 50
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
ğŸ² ç”Ÿæˆ 50 ä¸ªè½½è·...
   [1/50] ' union select 1,2,3--
   [10/50] 1' and 1=1--
   ...

ğŸ“Š è¯„ä¼° 50 ä¸ªè½½è·...
  - æ€»æ•°: 50
  - å”¯ä¸€: 48 (96.0%)
  - é‡å¤: 2
  - å¹³å‡é•¿åº¦: 45.2 å­—ç¬¦
  - æœ‰æ•ˆ: 46 (92.0%)
```

### 2. ç”Ÿæˆå¤§é‡è½½è·

```bash
python train/test_rl_model.py \
    --model_path ./models/rl_sqli_gpt2/final_model \
    --num_samples 1000 \
    --output_file ./generated_payloads.txt
```

### 3. è°ƒæ•´ç”Ÿæˆå‚æ•°

```bash
# æ›´éšæœºçš„ç”Ÿæˆ (æ¢ç´¢æ€§æ›´å¼º)
python train/test_rl_model.py \
    --model_path ./models/rl_sqli_gpt2/final_model \
    --temperature 1.5 \
    --top_k 100 \
    --num_samples 50

# æ›´ç¡®å®šæ€§çš„ç”Ÿæˆ (æ›´æ¥è¿‘è®­ç»ƒåˆ†å¸ƒ)
python train/test_rl_model.py \
    --model_path ./models/rl_sqli_gpt2/final_model \
    --temperature 0.7 \
    --top_p 0.9 \
    --num_samples 50
```

---

## ğŸ“Š è¯„ä¼°ä¸åŠŸèƒ½éªŒè¯

### 1. è¯„ä¼°WAFç»•è¿‡ç‡

```bash
python train/evaluate_rl.py \
    --model_path ./models/rl_sqli_gpt2/final_model \
    --waf_url http://localhost:8082 \
    --num_samples 100 \
    --output_file ./evaluation_results.json
```

### 2. åŠŸèƒ½æ€§éªŒè¯ï¼ˆDVWAï¼‰

```bash
python train/evaluate_rl.py \
    --model_path ./models/rl_sqli_gpt2/final_model \
    --waf_url http://localhost:8082 \
    --num_samples 100 \
    --functional_verify \
    --dvwa_login \
    --dvwa_username admin \
    --dvwa_password password \
    --fv_url http://localhost:8081/vulnerabilities/sqli/ \
    --fv_param id \
    --fv_method get \
    --fv_success_regex "First name|Surname" \
    --output_file ./evaluation_results.json
```

ä¸ä¼  `--fv_url` ä¼šè‡ªåŠ¨è¾“å‡º 100 ä¸ªç»•è¿‡æ ·æœ¬ä¾›äººå·¥æ£€æŸ¥ï¼š
`results/functional_verification_samples.json`ã€‚

---

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾å­˜ä¸è¶³ (OOM)

**è§£å†³æ–¹æ¡ˆ**:

1. å‡å°batch size:
```bash
python train/train_rl.py --batch_size 128 --mini_batch_size 8
```

2. å‡å°ç”Ÿæˆé•¿åº¦:
```bash
python train/train_rl.py --max_new_tokens 64
```

3. ä½¿ç”¨8-bité‡åŒ– (éœ€è¦ä¿®æ”¹ä»£ç ):
```python
# åœ¨ train_rl.py ä¸­ï¼ŒåŠ è½½æ¨¡å‹æ—¶:
model = AutoModelForCausalLMWithValueHead.from_pretrained(
    model_path,
    load_in_8bit=True
)
```

### Q2: å¹³å‡å¥–åŠ±ä¸€ç›´å¾ˆä½ (< 0.05)

**å¯èƒ½åŸå› **:

1. **å¥–åŠ±æ¨¡å‹è´¨é‡å·®**
   - æ£€æŸ¥Stage 2çš„æµ‹è¯•å‡†ç¡®ç‡ï¼Œåº”è¯¥ > 90%
   - è§£å†³: ç”¨æ›´å¤šæ•°æ®é‡æ–°è®­ç»ƒå¥–åŠ±æ¨¡å‹

2. **KLç³»æ•°å¤ªå¤§**
   - æ¨¡å‹ä¸æ•¢åç¦»é¢„è®­ç»ƒåˆ†å¸ƒ
   - è§£å†³: é™ä½ `--init_kl_coef` åˆ° 0.1

3. **é¢„è®­ç»ƒä¸å……åˆ†**
   - Stage 1çš„é¢„è®­ç»ƒæ•°æ®å¤ªå°‘
   - è§£å†³: ä½¿ç”¨æ›´å¤šæ•°æ®é‡æ–°é¢„è®­ç»ƒ

### Q3: ç”Ÿæˆçš„è½½è·éƒ½æ˜¯é‡å¤çš„

**è§£å†³æ–¹æ¡ˆ**:

1. å¢åŠ ç”Ÿæˆéšæœºæ€§:
```bash
python train/test_rl_model.py --temperature 1.5 --top_k 100
```

2. å¯èƒ½æ˜¯æ¨¡å‹è¿‡æ‹Ÿåˆäº†ï¼Œå°è¯•ï¼š
   - å‡å°‘è®­ç»ƒè½®æ•°
   - å¢å¤§KLç³»æ•°

### Q4: ç”Ÿæˆçš„è½½è·è¯­æ³•é”™è¯¯ç‡é«˜

**è§£å†³æ–¹æ¡ˆ**:

1. å¢å¤§KLç³»æ•°ï¼ˆä¿æŒæ›´æ¥è¿‘é¢„è®­ç»ƒåˆ†å¸ƒï¼‰:
```bash
python train/train_rl.py --init_kl_coef 0.3
```

2. æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹è´¨é‡ï¼ˆStage 1ï¼‰

### Q5: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢

**ä¼˜åŒ–æ–¹æ¡ˆ**:

1. ä½¿ç”¨æ›´å°çš„batch sizeä½†æ›´å¤šè½®æ•°:
```bash
python train/train_rl.py --batch_size 128 --total_episodes 40
```

2. å‡å°‘ç”Ÿæˆé•¿åº¦:
```bash
python train/train_rl.py --max_new_tokens 64
```

3. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (å·²é»˜è®¤å¯ç”¨):
```python
config.use_fp16 = True  # åœ¨ä»£ç ä¸­å·²å¯ç”¨
```

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶ç»“æ„

è®­ç»ƒå®Œæˆåï¼Œè¾“å‡ºç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
models/rl_sqli_gpt2/
â”œâ”€â”€ checkpoint-5/              # ç¬¬5è½®æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ config.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ checkpoint-10/             # ç¬¬10è½®æ£€æŸ¥ç‚¹
â”œâ”€â”€ checkpoint-15/             # ç¬¬15è½®æ£€æŸ¥ç‚¹
â”œâ”€â”€ checkpoint-20/             # ç¬¬20è½®æ£€æŸ¥ç‚¹
â”œâ”€â”€ final_model/               # ğŸ¯ æœ€ç»ˆæ¨¡å‹ (ä½¿ç”¨è¿™ä¸ª)
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â”œâ”€â”€ vocab.json
â”‚   â”œâ”€â”€ merges.txt
â”‚   â””â”€â”€ rl_config.json
â”œâ”€â”€ training_stats.json        # è®­ç»ƒç»Ÿè®¡
â””â”€â”€ rl_config.json             # è®­ç»ƒé…ç½®
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥

å®ŒæˆRLè®­ç»ƒåï¼Œä½ å¯ä»¥ï¼š

1. **é›†æˆåˆ°Webåº”ç”¨**
   - å°†æ¨¡å‹é›†æˆåˆ°åç«¯API
   - å®æ—¶ç”ŸæˆWAFç»•è¿‡è½½è·

2. **æŒç»­ä¼˜åŒ–**
   - æ”¶é›†æ¨¡å‹ç”Ÿæˆçš„æˆåŠŸæ¡ˆä¾‹
   - æ·»åŠ åˆ°è®­ç»ƒæ•°æ®ï¼Œé‡æ–°è®­ç»ƒ

3. **æ‰©å±•åˆ°å…¶ä»–æ”»å‡»ç±»å‹**
   - ä½¿ç”¨ç›¸åŒæ–¹æ³•è®­ç»ƒXSSã€RCEæ¨¡å‹
   - åªéœ€æ›¿æ¢é¢„è®­ç»ƒæ¨¡å‹å’Œå¥–åŠ±æ¨¡å‹

4. **è¯„ä¼°å’ŒåŸºå‡†æµ‹è¯•**
   - åœ¨çœŸå®WAFä¸Šæµ‹è¯•ç»•è¿‡ç‡
   - ä¸ä¼ ç»Ÿæ¨¡ç³Šæµ‹è¯•å·¥å…·å¯¹æ¯”

---

## ğŸ“š å‚è€ƒèµ„æ–™

- **è®ºæ–‡**: GPTFuzzer: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts
- **PPOç®—æ³•**: [Proximal Policy Optimization](https://arxiv.org/abs/1707.06347)
- **TRLåº“**: [Transformer Reinforcement Learning](https://github.com/huggingface/trl)
- **ç›¸å…³æ–‡æ¡£**:
  - [GPTFuzzer å¼ºåŒ–å­¦ä¹ é˜¶æ®µå¤ç°æŒ‡å—.md](./GPTFuzzer%20å¼ºåŒ–å­¦ä¹ é˜¶æ®µå¤ç°æŒ‡å—.md)
  - [GPTFuzzer è®ºæ–‡ç»†èŠ‚æ€»ç»“.md](./GPTFuzzer%20è®ºæ–‡ç»†èŠ‚æ€»ç»“.md)

---

## âš ï¸ é‡è¦æç¤º

1. **æ˜¾å­˜éœ€æ±‚**: 
   - æœ€ä½8GB (ä½¿ç”¨ä¼˜åŒ–å‚æ•°)
   - æ¨è12GB+ (å¯ç”¨è®ºæ–‡åŸå§‹å‚æ•°)

2. **è®­ç»ƒæ—¶é—´**:
   - RTX 4070: çº¦2-4å°æ—¶ (20è½®ï¼Œbatch_size=256)
   - CPU: ä¸æ¨è (å¤ªæ…¢)

3. **ä¼¦ç†ä½¿ç”¨**:
   - ä»…ç”¨äºå®‰å…¨æµ‹è¯•å’Œç ”ç©¶
   - ä¸å¾—ç”¨äºéæ³•æ”»å‡»
   - éµå®ˆå½“åœ°æ³•å¾‹æ³•è§„

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—è¾“å‡ºæˆ–æissueã€‚**
