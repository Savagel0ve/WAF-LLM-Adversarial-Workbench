# å¥–åŠ±æ¨¡åž‹è®­ç»ƒå¿«é€Ÿå¼€å§‹

5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹å¥–åŠ±æ¨¡åž‹è®­ç»ƒï¼

## ðŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤ 0: æ£€æŸ¥å‰ç½®æ¡ä»¶

```powershell
# 1. æ£€æŸ¥é¢„è®­ç»ƒæ¨¡åž‹æ˜¯å¦å­˜åœ¨
Test-Path .\models\pretrain_sqli_gpt2_small

# 2. æ£€æŸ¥ WAF æ˜¯å¦è¿è¡Œ
.\test_reward_waf.ps1
```

å¦‚æžœ WAF æµ‹è¯•å¤±è´¥ï¼Œè¯·å¯åŠ¨ WAFï¼š

```powershell
cd waf-bench
docker-compose up -d
```

### æ­¥éª¤ 1: è®­ç»ƒ SQLi å¥–åŠ±æ¨¡åž‹ï¼ˆæŽ¨èå…ˆåšè¿™ä¸ªï¼‰

```powershell
.\train_reward_sqli.ps1
```

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. âœ… ä»Ž SQLi æ•°æ®é‡‡æ · 4000 æ¡
2. âœ… é€šè¿‡ WAF æµ‹è¯•å¹¶æ‰“æ ‡ç­¾ï¼ˆ~5-10åˆ†é’Ÿï¼‰
3. âœ… è®­ç»ƒ GPT-2 åˆ†ç±»æ¨¡åž‹ï¼ˆ~10-15åˆ†é’Ÿï¼‰
4. âœ… åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°

**æ€»è€—æ—¶**: çº¦ 15-25 åˆ†é’Ÿ

### æ­¥éª¤ 2: æµ‹è¯•æ¨¡åž‹

```powershell
# å•ä¸ª payload æµ‹è¯•
python train\test_reward_model.py `
    --model_path .\models\reward_sqli\final_reward_model `
    --payload "' OR 1=1 --"

# æ‰¹é‡æµ‹è¯•
python train\test_reward_model.py `
    --model_path .\models\reward_sqli\final_reward_model `
    --payload_file .\data\processed\sqli\test.txt
```

### æ­¥éª¤ 3: æŸ¥çœ‹è®­ç»ƒç»“æžœ

```powershell
# å¯åŠ¨ TensorBoard
tensorboard --logdir .\models\reward_sqli\logs

# åœ¨æµè§ˆå™¨æ‰“å¼€: http://localhost:6006
```

## ðŸ“Š é¢„æœŸç»“æžœ

### è®­ç»ƒæŒ‡æ ‡

| æŒ‡æ ‡ | SQLi ç›®æ ‡ | XSS ç›®æ ‡ |
|------|-----------|----------|
| AUC | > 99% | > 98% |
| F1-Score | > 95% | > 95% |
| Accuracy | > 95% | > 95% |

### è¾“å‡ºç¤ºä¾‹

```
æµ‹è¯•é›†ç»“æžœ:
  test_accuracy: 0.9612
  test_f1: 0.9583
  test_precision: 0.9521
  test_recall: 0.9647
  test_auc: 0.9924
```

å¦‚æžœ AUC < 95%ï¼Œå¯èƒ½éœ€è¦ï¼š
- å¢žåŠ æ•°æ®é‡
- è°ƒæ•´è¶…å‚æ•°
- æ£€æŸ¥æ•°æ®è´¨é‡

## ðŸ”§ è‡ªå®šä¹‰è®­ç»ƒ

### ä¿®æ”¹é‡‡æ ·æ•°é‡

```powershell
# å¿«é€Ÿæµ‹è¯•ï¼ˆå°æ•°æ®é‡ï¼‰
python train\generate_labeled_data.py `
    --attack_type sqli `
    --input_file .\data\processed\sqli\train.txt `
    --output_dir .\data\labeled `
    --num_samples 1000  # é™ä½Žåˆ° 1000

# é«˜è´¨é‡è®­ç»ƒï¼ˆå¤§æ•°æ®é‡ï¼‰
python train\generate_labeled_data.py `
    --num_samples 8000  # å¢žåŠ åˆ° 8000
```

### ä¿®æ”¹è®­ç»ƒå‚æ•°

```powershell
python train\train_reward_model.py `
    --pretrained_model_path .\models\pretrain_sqli_gpt2_small `
    --data_path .\data\labeled `
    --output_dir .\models\reward_sqli_custom `
    --batch_size 16 `       # é™ä½Žæ˜¾å­˜å ç”¨
    --epochs 6 `            # å¢žåŠ è®­ç»ƒè½®æ•°
    --learning_rate 1e-5    # é™ä½Žå­¦ä¹ çŽ‡
```

### ä½¿ç”¨ä¸åŒçš„ WAF

```powershell
# ModSecurity (é»˜è®¤)
python train\generate_labeled_data.py `
    --waf_url http://localhost:8081

# Naxsi
python train\generate_labeled_data.py `
    --waf_url http://localhost:8082

# è‡ªå®šä¹‰ WAF
python train\generate_labeled_data.py `
    --waf_url http://your-waf-server:port
```

## ðŸ“ è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®ŒæˆåŽï¼Œä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
data/labeled/
â”œâ”€â”€ sqli_train.csv          # è®­ç»ƒæ•°æ®
â”œâ”€â”€ sqli_val.csv            # éªŒè¯æ•°æ®
â”œâ”€â”€ sqli_test.csv           # æµ‹è¯•æ•°æ®
â”œâ”€â”€ sqli_train_full.json    # å®Œæ•´ä¿¡æ¯ï¼ˆå«å“åº”æ—¶é—´ç­‰ï¼‰
â””â”€â”€ sqli_stats.json         # æ•°æ®ç»Ÿè®¡

models/reward_sqli/
â”œâ”€â”€ final_reward_model/     # æœ€ç»ˆæ¨¡åž‹ï¼ˆç”¨äºŽ PPOï¼‰
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ tokenizer_config.json
â”‚   â””â”€â”€ vocab.json
â”œâ”€â”€ checkpoint-*/           # è®­ç»ƒæ£€æŸ¥ç‚¹
â”œâ”€â”€ logs/                   # TensorBoard æ—¥å¿—
â””â”€â”€ test_results.json       # æµ‹è¯•ç»“æžœ
```

## ðŸ› å¸¸è§é—®é¢˜

### Q1: WAF è¿žæŽ¥å¤±è´¥ï¼Ÿ

```powershell
# æ£€æŸ¥ WAF çŠ¶æ€
cd waf-bench
docker-compose ps

# é‡å¯ WAF
docker-compose restart

# æŸ¥çœ‹ WAF æ—¥å¿—
docker-compose logs -f
```

### Q2: æ˜¾å­˜ä¸è¶³ï¼Ÿ

```powershell
# æ–¹æ¡ˆ1: é™ä½Ž batch size
python train\train_reward_model.py --batch_size 16

# æ–¹æ¡ˆ2: ä¸ä½¿ç”¨ FP16ï¼ˆä¸æŽ¨èï¼‰
python train\train_reward_model.py --fp16 false

# æ–¹æ¡ˆ3: å‡å°‘åºåˆ—é•¿åº¦
python train\train_reward_model.py --max_length 64
```

### Q3: è®­ç»ƒå¤ªæ…¢ï¼Ÿ

```powershell
# å‡å°‘æ•°æ®é‡ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
python train\generate_labeled_data.py --num_samples 1000

# å‡å°‘ epoch
python train\train_reward_model.py --epochs 2

# å¢žåŠ  batch sizeï¼ˆå¦‚æžœæ˜¾å­˜å¤Ÿï¼‰
python train\train_reward_model.py --batch_size 64
```

### Q4: æ¨¡åž‹æ€§èƒ½ä¸ä½³ï¼Ÿ

1. **å¢žåŠ æ•°æ®é‡**: `--num_samples 8000`
2. **å¢žåŠ è®­ç»ƒè½®æ•°**: `--epochs 6`
3. **è°ƒæ•´å­¦ä¹ çŽ‡**: `--learning_rate 1e-5`
4. **æ£€æŸ¥æ•°æ®è´¨é‡**: æŸ¥çœ‹ `sqli_stats.json`
5. **å¹³è¡¡æ•°æ®é›†**: `--balance_ratio 0.6`

## ðŸŽ¯ ä¸‹ä¸€æ­¥

è®­ç»ƒå®ŒæˆåŽï¼š

### 1. è¯„ä¼°æ¨¡åž‹

```powershell
python train\test_reward_model.py `
    --model_path .\models\reward_sqli\final_reward_model `
    --payload_file .\data\processed\sqli\test.txt
```

### 2. åœ¨ä»£ç ä¸­ä½¿ç”¨

```python
from train.test_reward_model import RewardModelInference

# åŠ è½½æ¨¡åž‹
reward_model = RewardModelInference(
    model_path="./models/reward_sqli/final_reward_model"
)

# é¢„æµ‹
payloads = ["' OR 1=1 --", "UNION SELECT", "normal input"]
probs = reward_model.predict_batch(payloads)

for payload, prob in zip(payloads, probs):
    print(f"{prob:.3f} | {payload}")
```

### 3. è¿›å…¥ PPO é˜¶æ®µ

å¥–åŠ±æ¨¡åž‹å°†ç”¨äºŽå¼ºåŒ–å­¦ä¹ ï¼š

```python
# åœ¨ PPO è®­ç»ƒä¸­ä½¿ç”¨
reward_model_path = "./models/reward_sqli/final_reward_model"
```

## ðŸ“š å‚è€ƒæ–‡æ¡£

- **è¯¦ç»†æŒ‡å—**: `README_REWARD_MODEL.md`
- **è®ºæ–‡ç»†èŠ‚**: `GPTFuzzer è®ºæ–‡ç»†èŠ‚æ€»ç»“.md`
- **è®­ç»ƒæŒ‡å—**: `WAF ç»•è¿‡å¥–åŠ±æ¨¡åž‹è®­ç»ƒæŒ‡å—.md`

## âš¡ å®Œæ•´æµç¨‹ç¤ºä¾‹

```powershell
# 1. æµ‹è¯• WAF
.\test_reward_waf.ps1

# 2. è®­ç»ƒ SQLi æ¨¡åž‹
.\train_reward_sqli.ps1

# 3. è®­ç»ƒ XSS æ¨¡åž‹
.\train_reward_xss.ps1

# 4. æµ‹è¯•æ¨¡åž‹
python train\test_reward_model.py `
    --model_path .\models\reward_sqli\final_reward_model `
    --payload "' OR 1=1 --"

# 5. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tensorboard --logdir .\models\reward_sqli\logs
```

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** 

- æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: `logs/reward_training.log`
- æäº¤ Issue: [GitHub Issues](https://github.com/your-repo/issues)
- å‚è€ƒæ–‡æ¡£: `README_REWARD_MODEL.md`
