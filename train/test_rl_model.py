"""
æµ‹è¯•å¼ºåŒ–å­¦ä¹ è®­ç»ƒåçš„æ¨¡å‹
æ”¯æŒ Qwen2.5-Coder å’Œå…¶ä»–ç°ä»£ LLM

ç”Ÿæˆ SQL æ³¨å…¥è½½è·å¹¶è¯„ä¼°è´¨é‡
"""

import os
import sys
import torch
import argparse
from typing import List, Dict
from transformers import AutoTokenizer, AutoModelForCausalLM

try:
    from verifier import SQLiVerifier
except ImportError:
    SQLiVerifier = None
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥SQLiVerifierï¼Œå°†è·³è¿‡è¯­æ³•éªŒè¯")


class RLModelTester:
    """RLæ¨¡å‹æµ‹è¯•å™¨ - æ”¯æŒ Qwen2.5-Coder å’Œå…¶ä»–ç°ä»£ LLM"""
    
    def __init__(self, model_path: str, device: str = "cuda"):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨
        
        Args:
            model_path: RLè®­ç»ƒåçš„æ¨¡å‹è·¯å¾„
            device: è¿è¡Œè®¾å¤‡
        """
        self.device = device if torch.cuda.is_available() else "cpu"
        
        print(f"ğŸ” åŠ è½½æ¨¡å‹: {model_path}")
        
        # åŠ è½½ tokenizer (ä½¿ç”¨ AutoTokenizer æ”¯æŒå„ç§æ¨¡å‹)
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_path,
            trust_remote_code=True,
            padding_side="left"
        )
        
        if self.tokenizer.pad_token is None:
            if self.tokenizer.eos_token:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            else:
                self.tokenizer.add_special_tokens({'pad_token': '[PAD]'})
        
        # åŠ è½½æ¨¡å‹
        self.model = AutoModelForCausalLM.from_pretrained(
            model_path,
            trust_remote_code=True,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
            device_map="auto" if self.device == "cuda" else None,
        )
        
        if self.device != "cuda":
            self.model.to(self.device)
        
        self.model.eval()
        
        # åˆå§‹åŒ–éªŒè¯å™¨
        self.verifier = SQLiVerifier() if SQLiVerifier else None
        
        print(f"   æ¨¡å‹ç±»å‹: {type(self.model).__name__}")
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: {self.device})")
    
    def generate_payloads(
        self,
        num_samples: int = 10,
        max_length: int = 128,
        temperature: float = 1.0,
        top_k: int = 50,
        top_p: float = 0.95,
        do_sample: bool = True,
    ) -> List[str]:
        """
        ç”Ÿæˆè½½è·
        
        Args:
            num_samples: ç”Ÿæˆæ•°é‡
            max_length: æœ€å¤§é•¿åº¦
            temperature: æ¸©åº¦å‚æ•° (è¶Šé«˜è¶Šéšæœº)
            top_k: Top-Ké‡‡æ ·
            top_p: Nucleusé‡‡æ ·
            do_sample: æ˜¯å¦ä½¿ç”¨é‡‡æ ·
            
        Returns:
            ç”Ÿæˆçš„è½½è·åˆ—è¡¨
        """
        print(f"\nğŸ² ç”Ÿæˆ {num_samples} ä¸ªè½½è·...")
        print(f"   å‚æ•°: temp={temperature}, top_k={top_k}, top_p={top_p}")
        
        payloads = []
        
        with torch.no_grad():
            for i in range(num_samples):
                # åˆ›å»ºèµ·å§‹è¾“å…¥ (BOS token)
                input_ids = torch.tensor(
                    [[self.tokenizer.bos_token_id]],
                    dtype=torch.long,
                    device=self.device
                )
                
                attention_mask = torch.ones_like(input_ids)

                # ç”Ÿæˆ
                output = self.model.generate(
                    input_ids,
                    attention_mask=attention_mask,
                    max_length=max_length,
                    temperature=temperature,
                    top_k=top_k,
                    top_p=top_p,
                    do_sample=do_sample,
                    pad_token_id=self.tokenizer.eos_token_id,
                    eos_token_id=self.tokenizer.eos_token_id,
                    num_return_sequences=1,
                )
                
                # è§£ç 
                payload = self.tokenizer.decode(output[0], skip_special_tokens=True)
                payloads.append(payload)
                
                # å®æ—¶æ˜¾ç¤º
                if (i + 1) % 10 == 0 or i == 0:
                    print(f"   [{i+1}/{num_samples}] {payload[:80]}...")
        
        print(f"âœ“ ç”Ÿæˆå®Œæˆ")
        return payloads
    
    def evaluate_payloads(self, payloads: List[str]) -> Dict:
        """
        è¯„ä¼°ç”Ÿæˆçš„è½½è·
        
        Args:
            payloads: è½½è·åˆ—è¡¨
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        print(f"\nğŸ“Š è¯„ä¼° {len(payloads)} ä¸ªè½½è·...")
        
        results = {
            'total': len(payloads),
            'valid': 0,
            'invalid': 0,
            'avg_length': 0,
            'unique': 0,
            'duplicates': 0,
        }
        
        # å»é‡
        unique_payloads = list(set(payloads))
        results['unique'] = len(unique_payloads)
        results['duplicates'] = len(payloads) - len(unique_payloads)
        
        # å¹³å‡é•¿åº¦
        lengths = [len(p) for p in payloads]
        results['avg_length'] = sum(lengths) / len(lengths) if lengths else 0
        
        # è¯­æ³•éªŒè¯
        if self.verifier:
            print("   æ­£åœ¨éªŒè¯SQLè¯­æ³•...")
            for payload in payloads:
                if self.verifier.verify(payload):
                    results['valid'] += 1
                else:
                    results['invalid'] += 1
            
            results['valid_rate'] = results['valid'] / results['total'] * 100
        else:
            print("   (è·³è¿‡è¯­æ³•éªŒè¯)")
            results['valid'] = -1
            results['invalid'] = -1
            results['valid_rate'] = -1
        
        # æ‰“å°ç»“æœ
        print(f"\nè¯„ä¼°ç»“æœ:")
        print(f"  - æ€»æ•°: {results['total']}")
        print(f"  - å”¯ä¸€: {results['unique']} ({results['unique']/results['total']*100:.1f}%)")
        print(f"  - é‡å¤: {results['duplicates']}")
        print(f"  - å¹³å‡é•¿åº¦: {results['avg_length']:.1f} å­—ç¬¦")
        
        if results['valid'] >= 0:
            print(f"  - æœ‰æ•ˆ: {results['valid']} ({results['valid_rate']:.1f}%)")
            print(f"  - æ— æ•ˆ: {results['invalid']}")
        
        return results
    
    def show_samples(self, payloads: List[str], num_show: int = 10):
        """æ˜¾ç¤ºæ ·ä¾‹è½½è·"""
        print(f"\nğŸ“„ è½½è·æ ·ä¾‹ (å‰{num_show}ä¸ª):")
        print("="*80)
        
        for i, payload in enumerate(payloads[:num_show]):
            print(f"\n[{i+1}]")
            print(payload)
            print("-"*80)


def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯•RLè®­ç»ƒåçš„æ¨¡å‹")
    
    parser.add_argument(
        "--model_path",
        type=str,
        required=True,
        help="RLæ¨¡å‹è·¯å¾„ (ä¾‹å¦‚: ./models/rl_sqli_gpt2/final_model)"
    )
    parser.add_argument(
        "--num_samples",
        type=int,
        default=50,
        help="ç”Ÿæˆæ ·æœ¬æ•°é‡"
    )
    parser.add_argument(
        "--max_length",
        type=int,
        default=128,
        help="æœ€å¤§ç”Ÿæˆé•¿åº¦"
    )
    parser.add_argument(
        "--temperature",
        type=float,
        default=1.0,
        help="ç”Ÿæˆæ¸©åº¦ (0.1-2.0, è¶Šé«˜è¶Šéšæœº)"
    )
    parser.add_argument(
        "--top_k",
        type=int,
        default=50,
        help="Top-Ké‡‡æ ·"
    )
    parser.add_argument(
        "--top_p",
        type=float,
        default=0.95,
        help="Nucleusé‡‡æ ·"
    )
    parser.add_argument(
        "--output_file",
        type=str,
        default=None,
        help="ä¿å­˜ç”Ÿæˆç»“æœçš„æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda",
        help="è¿è¡Œè®¾å¤‡ (cuda/cpu)"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹ä¸å­˜åœ¨: {args.model_path}")
        sys.exit(1)
    
    print("="*80)
    print("ğŸ§ª RLæ¨¡å‹æµ‹è¯•å·¥å…·")
    print("="*80)
    print(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"ç”Ÿæˆæ•°é‡: {args.num_samples}")
    print(f"æ¸©åº¦: {args.temperature}")
    print("="*80)
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = RLModelTester(args.model_path, args.device)
    
    # ç”Ÿæˆè½½è·
    payloads = tester.generate_payloads(
        num_samples=args.num_samples,
        max_length=args.max_length,
        temperature=args.temperature,
        top_k=args.top_k,
        top_p=args.top_p,
    )
    
    # è¯„ä¼°
    results = tester.evaluate_payloads(payloads)
    
    # æ˜¾ç¤ºæ ·ä¾‹
    tester.show_samples(payloads, num_show=min(10, len(payloads)))
    
    # ä¿å­˜ç»“æœ
    if args.output_file:
        print(f"\nğŸ’¾ ä¿å­˜ç»“æœåˆ°: {args.output_file}")
        with open(args.output_file, 'w', encoding='utf-8') as f:
            for i, payload in enumerate(payloads):
                f.write(f"{payload}\n")
        print(f"âœ“ å·²ä¿å­˜ {len(payloads)} ä¸ªè½½è·")
    
    print("\n" + "="*80)
    print("âœ“ æµ‹è¯•å®Œæˆ!")
    print("="*80)
    
    # è¿”å›è¯„ä¼°ç»“æœ
    return results


if __name__ == "__main__":
    main()
