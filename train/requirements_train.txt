# ============================================================
# 深度学习核心库 - 支持 Qwen2.5-Coder 和其他现代 LLM
# 针对 RTX 4070 8GB 优化
# ============================================================

# PyTorch (建议使用 CUDA 12.1+)
torch>=2.1.0
torchvision>=0.16.0

# Transformers - 支持 Qwen2.5, Phi-3, Mistral 等
transformers>=4.40.0
tokenizers>=0.15.0
huggingface-hub>=0.20.0

# 强化学习
trl>=0.8.0  # PPO 实现和 RLHF 工具 (支持新模型)
peft>=0.10.0  # 参数高效微调 (LoRA/QLoRA)

# 数据处理
datasets>=2.18.0
accelerate>=0.28.0  # 分布式训练和混合精度
scipy>=1.12.0
pandas>=2.2.0
numpy>=1.26.0

# ============================================================
# 显存优化 (8GB 显存必装)
# ============================================================
bitsandbytes>=0.43.0  # 8-bit/4-bit 量化和优化器

# Flash Attention 2 (可选，需要单独安装)
# pip install flash-attn --no-build-isolation
# 或者: pip install ninja && pip install flash-attn --no-build-isolation

# ============================================================
# 实验跟踪
# ============================================================
wandb>=0.16.0
tensorboard>=2.16.0

# ============================================================
# Qwen 模型支持 (可选，某些功能需要)
# ============================================================
tiktoken>=0.6.0  # 某些模型的 tokenizer 需要
einops>=0.7.0  # 某些模型架构需要
transformers_stream_generator>=0.0.4  # 流式生成

# ============================================================
# Grammar 解析
# ============================================================
pyparsing>=3.1.0
lark>=1.1.0  # lark-parser 已更名为 lark

# ============================================================
# WAF 测试和验证
# ============================================================
requests>=2.31.0
httpx>=0.27.0  # 异步 HTTP 客户端
aiohttp>=3.9.0  # 异步请求
selenium>=4.18.0
webdriver-manager>=4.0.0

# ============================================================
# 数据库测试 (SQLi 验证)
# ============================================================
mysql-connector-python>=8.3.0
psycopg2-binary>=2.9.9

# ============================================================
# 机器学习评估
# ============================================================
scikit-learn>=1.4.0

# ============================================================
# 其他工具
# ============================================================
sentencepiece>=0.2.0  # 某些模型的 tokenizer 需要
protobuf>=4.25.0  # sentencepiece 依赖
tqdm>=4.66.0
pytest>=8.0.0
rich>=13.7.0  # 美化输出
typer>=0.9.0  # CLI 工具

# ============================================================
# 可选: 更多模型支持
# ============================================================
# auto-gptq>=0.7.0  # GPTQ 量化支持
# optimum>=1.17.0  # 模型优化
